# AI/ML Technical Assessment Tasks

This repository contains **specialized technical assessment tasks** focusing on AI/ML engineering skills. The tasks are designed to evaluate your approach to **problem-solving** in machine learning contexts and ability to **efficiently implement and optimize ML models**.

## 🎯 Key Points

1. **Focus on Practical Implementation:** These tasks **are NOT** about building **~~production-ready systems~~**. We want to see your approach to ML engineering challenges.
2. **Time Expectation:** Most tasks are designed to be completed in 3-6 hours by an experienced AI/ML engineer.
3. **Evaluation Priority:** Problem-solving approach > Code completeness > Perfect accuracy
4. **Tool Freedom:** Use any libraries/frameworks you prefer - the end result matters most

## 💡 What We're Looking For

### Smart Engineering Decisions:

- Choose appropriate model architectures and optimization techniques
- Make sensible trade-offs between accuracy and efficiency
- Demonstrate understanding of ML model deployment considerations
- Document your decisions and thought process

### Technical Skills:

- Solid implementation of key ML components
- Clean, readable code structure
- Understanding of performance considerations
- Effective data preprocessing and model evaluation

### Problem Solving:

- How you approach complex ML requirements
- Which techniques you choose (and why)
- How you debug and improve model performance
- Your analysis of results and limitations

## 🚀 Tasks Overview

### Medical Image Segmentation with U-Net
> [Detailed documentation](./tasks/Medical-Image-Segmentation-task.md)

1. Implement U-Net architecture for medical image segmentation
2. Develop effective preprocessing for ultrasound images
3. Apply optimization techniques for edge deployment
4. Evaluate model performance with appropriate metrics

### LLM Optimization for Edge Devices
> [Detailed documentation](./tasks/LLM-Optimization-task.md)

1. Optimize a pre-trained language model for edge deployment
2. Implement techniques like knowledge distillation, pruning, and quantization
3. Benchmark performance metrics before and after optimization
4. Document deployment considerations

### Domain-Specific Speech Recognition
> [Detailed documentation](./tasks/Domain-Speech-Recognition-task.md)

1. Create a synthetic dataset for domain-specific speech recognition
2. Fine-tune Whisper model using LoRA or Axolotl
3. Implement robust preprocessing for noisy audio
4. Evaluate and compare with baseline model

## 📝 Getting Started

### Choose Your Focus:

1. Pick the task that best matches your skills and interests
2. Read through the task documentation completely
3. Plan your approach before starting implementation

### Quick Setup:

1. Fork this repository
2. Use the provided code examples as starting points
3. Focus on the core ML components first

## Submission:

1. Working solution with clear documentation
2. Include all code, Jupyter notebooks, or scripts used
3. Technical report describing your approach, experiments, and results
4. Notes about trade-offs made and potential improvements

## ⚡ Example Approach

### A good submission might include:

- Clean, organized code with clear structure
- Well-documented experiments and parameter choices
- Visualizations of results and model performance
- Analysis of optimization techniques and their impact
- Thoughtful discussion of limitations and future work

### ❓ Questions?

- Open an issue for technical questions
- Contact [team@libraxis.dev] for scope clarification
- We're happy to discuss your approach!

## 🎓 Evaluation Criteria

### We value:

1. Clean, maintainable code
2. Smart engineering decisions
3. Clear documentation of experiments and results
4. Working implementation (even if limited)
5. Thoughtful analysis of your solution

### We don't expect:

- State-of-the-art results
- Perfect accuracy/performance
- Comprehensive solution to all task aspects
- Production-ready deployment

## &nbsp;
> 📖 License
> MIT
