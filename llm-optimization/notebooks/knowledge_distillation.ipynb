{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation for LLM Optimization\n",
    "\n",
    "This notebook implements knowledge distillation to optimize DistilBERT for deployment on edge devices. Knowledge distillation is a technique where a smaller model (student) is trained to mimic the behavior of a larger, more powerful model (teacher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from src.models.distilbert import load_distilbert_model, get_device\n",
    "from src.models.knowledge_distillation import create_student_model, DistillationTrainer\n",
    "from src.data.dataset import load_and_prepare_data, prepare_batch_for_model\n",
    "from src.utils.metrics import measure_performance, save_metrics, print_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 2  # Binary classification\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"glue\"\n",
    "DATASET_CONFIG = \"sst2\"  # Stanford Sentiment Treebank\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# Student model configuration\n",
    "STUDENT_NUM_LAYERS = 2  # Reduced from 6 in the original DistilBERT\n",
    "\n",
    "# Training configuration\n",
    "LEARNING_RATE = 5e-5\n",
    "EPOCHS = 3\n",
    "TEMPERATURE = 2.0\n",
    "ALPHA = 0.5  # Balance between hard and soft loss\n",
    "EVAL_EVERY = 100  # Evaluate every N steps\n",
    "\n",
    "# Output path\n",
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Device\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Teacher Model and Data\n",
    "\n",
    "First, we'll load the teacher model (DistilBERT) and prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher model and tokenizer\n",
    "print(f\"Loading pre-trained {MODEL_NAME} model as teacher...\")\n",
    "teacher_model, tokenizer = load_distilbert_model(MODEL_NAME, NUM_LABELS)\n",
    "\n",
    "# Load and prepare dataset\n",
    "print(\"Loading dataset and preparing data loaders...\")\n",
    "tokenizer, train_dataloader, eval_dataloader = load_and_prepare_data(\n",
    "    tokenizer, \n",
    "    dataset_name=DATASET_NAME, \n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Student Model\n",
    "\n",
    "Now, we'll create a smaller student model with fewer transformer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create student model with reduced number of layers\n",
    "print(f\"Creating student model with {STUDENT_NUM_LAYERS} layers (reduced from 6 in original)...\")\n",
    "student_model = create_student_model(\n",
    "    teacher_model=teacher_model,\n",
    "    num_layers=STUDENT_NUM_LAYERS,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "# Compare the number of parameters in teacher vs student\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "student_params = sum(p.numel() for p in student_model.parameters())\n",
    "\n",
    "print(f\"Teacher model parameters: {teacher_params:,}\")\n",
    "print(f\"Student model parameters: {student_params:,}\")\n",
    "print(f\"Reduction: {(1 - student_params / teacher_params) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Student Model using Knowledge Distillation\n",
    "\n",
    "We'll train the student to mimic the teacher's behavior using knowledge distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer for the student model\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Define a function to prepare batch (reusing from baseline)\n",
    "def prepare_batch(batch, device):\n",
    "    return prepare_batch_for_model(batch, device)\n",
    "\n",
    "# Create distillation trainer\n",
    "trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    temperature=TEMPERATURE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the student model\n",
    "print(\"Starting knowledge distillation training...\")\n",
    "training_stats = trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    alpha=ALPHA,\n",
    "    eval_every=EVAL_EVERY,\n",
    "    prepare_batch_fn=prepare_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Compare Teacher vs Student\n",
    "\n",
    "Compare the performance of the original teacher model and our distilled student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and evaluation accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot training loss\n",
    "ax1.plot(training_stats['train_losses'])\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Training Steps')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot evaluation accuracy\n",
    "eval_steps = [EVAL_EVERY * (i+1) for i in range(len(training_stats['eval_accuracies']))]\n",
    "ax2.plot(eval_steps, training_stats['eval_accuracies'])\n",
    "ax2.set_title('Evaluation Accuracy')\n",
    "ax2.set_xlabel('Training Steps')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline metrics to compare with\n",
    "baseline_metrics = torch.load(OUTPUT_DIR / \"baseline_metrics.pt\")\n",
    "\n",
    "# Measure student performance\n",
    "print(\"Measuring student model performance...\")\n",
    "student_metrics = measure_performance(student_model, eval_dataloader, DEVICE, prepare_batch)\n",
    "\n",
    "# Save student metrics\n",
    "save_metrics(student_metrics, file_path=OUTPUT_DIR / \"student_metrics.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and compare metrics\n",
    "print(\"\\n===== Teacher Model (Baseline) =====\")\n",
    "print_metrics(\n",
    "    baseline_metrics, \n",
    "    model_name=MODEL_NAME, \n",
    "    dataset_info=f\"Text Classification - {DATASET_NAME}/{DATASET_CONFIG}\"\n",
    ")\n",
    "\n",
    "print(\"\\n===== Student Model (Distilled) =====\")\n",
    "print_metrics(\n",
    "    student_metrics, \n",
    "    model_name=f\"Distilled {MODEL_NAME} ({STUDENT_NUM_LAYERS} layers)\", \n",
    "    dataset_info=f\"Text Classification - {DATASET_NAME}/{DATASET_CONFIG}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics for comparison\n",
    "size_reduction = 1 - (student_metrics['model_size_mb'] / baseline_metrics['model_size_mb'])\n",
    "speed_improvement = baseline_metrics['avg_latency_seconds'] / student_metrics['avg_latency_seconds'] \n",
    "accuracy_retention = student_metrics['accuracy'] / baseline_metrics['accuracy']\n",
    "\n",
    "print(\"\\n===== Performance Comparison =====\")\n",
    "print(f\"Size reduction: {size_reduction * 100:.2f}%\")\n",
    "print(f\"Speed improvement: {speed_improvement:.2f}x\")\n",
    "print(f\"Accuracy retention: {accuracy_retention * 100:.2f}%\")\n",
    "\n",
    "# Check against optimization targets\n",
    "print(\"\\n===== Optimization Targets =====\")\n",
    "print(f\"Size target (50% reduction): {'✅ Achieved' if size_reduction >= 0.5 else '❌ Not achieved'}\")\n",
    "print(f\"Accuracy target (90% retention): {'✅ Achieved' if accuracy_retention >= 0.9 else '❌ Not achieved'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size, speed, and accuracy comparison\n",
    "labels = ['Teacher', 'Student']\n",
    "\n",
    "# Prepare data for comparison\n",
    "sizes = [baseline_metrics['model_size_mb'], student_metrics['model_size_mb']]\n",
    "latencies = [baseline_metrics['avg_latency_ms'], student_metrics['avg_latency_ms']]\n",
    "accuracies = [baseline_metrics['accuracy'] * 100, student_metrics['accuracy'] * 100]\n",
    "params = [baseline_metrics['num_parameters'] / 1e6, student_metrics['num_parameters'] / 1e6]\n",
    "\n",
    "# Create bar chart comparisons\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Size comparison\n",
    "axs[0, 0].bar(labels, sizes)\n",
    "axs[0, 0].set_title('Model Size (MB)')\n",
    "axs[0, 0].set_ylabel('Size (MB)')\n",
    "for i, v in enumerate(sizes):\n",
    "    axs[0, 0].text(i, v + 2, f\"{v:.2f}\", ha='center')\n",
    "\n",
    "# Latency comparison\n",
    "axs[0, 1].bar(labels, latencies)\n",
    "axs[0, 1].set_title('Inference Latency (ms)')\n",
    "axs[0, 1].set_ylabel('Latency (ms)')\n",
    "for i, v in enumerate(latencies):\n",
    "    axs[0, 1].text(i, v + 2, f\"{v:.2f}\", ha='center')\n",
    "\n",
    "# Accuracy comparison\n",
    "axs[1, 0].bar(labels, accuracies)\n",
    "axs[1, 0].set_title('Accuracy (%)')\n",
    "axs[1, 0].set_ylabel('Accuracy (%)')\n",
    "for i, v in enumerate(accuracies):\n",
    "    axs[1, 0].text(i, v + 1, f\"{v:.2f}%\", ha='center')\n",
    "\n",
    "# Parameter count comparison\n",
    "axs[1, 1].bar(labels, params)\n",
    "axs[1, 1].set_title('Number of Parameters (Millions)')\n",
    "axs[1, 1].set_ylabel('Parameters (M)')\n",
    "for i, v in enumerate(params):\n",
    "    axs[1, 1].text(i, v + 1, f\"{v:.2f}M\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'knowledge_distillation_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Optimized Model\n",
    "\n",
    "Save the student model for later use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the student model\n",
    "student_save_path = OUTPUT_DIR / \"distilled_model\"\n",
    "student_save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "student_model.save_pretrained(student_save_path)\n",
    "tokenizer.save_pretrained(student_save_path)\n",
    "\n",
    "print(f\"Student model saved to {student_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Conclusion\n",
    "\n",
    "Summarize the results of knowledge distillation for our LLM optimization task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of knowledge distillation results\n",
    "print(\"===== Knowledge Distillation Summary =====\")\n",
    "print(f\"\\nTeacher model: {baseline_metrics['num_parameters']:,} parameters, {baseline_metrics['model_size_mb']:.2f} MB\")\n",
    "print(f\"Student model: {student_metrics['num_parameters']:,} parameters, {student_metrics['model_size_mb']:.2f} MB\")\n",
    "print(f\"Size reduction: {size_reduction * 100:.2f}%\")\n",
    "print(f\"\\nTeacher accuracy: {baseline_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Student accuracy: {student_metrics['accuracy'] * 100:.2f}%\")\n",
    "print(f\"Accuracy retention: {accuracy_retention * 100:.2f}%\")\n",
    "print(f\"\\nTeacher inference time: {baseline_metrics['avg_latency_ms']:.2f} ms\")\n",
    "print(f\"Student inference time: {student_metrics['avg_latency_ms']:.2f} ms\")\n",
    "print(f\"Speed improvement: {speed_improvement:.2f}x\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "if size_reduction >= 0.5 and accuracy_retention >= 0.9:\n",
    "    print(\"✅ Knowledge distillation successfully achieved our optimization targets.\")\n",
    "elif size_reduction >= 0.5:\n",
    "    print(\"⚠️ Size reduction target was met, but accuracy retention fell below the 90% target.\")\n",
    "elif accuracy_retention >= 0.9:\n",
    "    print(\"⚠️ Accuracy retention target was met, but size reduction fell below the 50% target.\")\n",
    "else:\n",
    "    print(\"❌ Neither size reduction nor accuracy retention targets were met.\")\n",
    "\n",
    "print(\"\\nNext steps could include:\")\n",
    "print(\"- Tuning knowledge distillation hyperparameters (temperature, alpha)\")\n",
    "print(\"- Combining distillation with other optimization approaches\")\n",
    "print(\"- Further reducing the student model size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}